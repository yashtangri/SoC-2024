I have used all the 3 models that were mentioned in the question and for the 4th model i have used "microsoft/Phi-3-mini-128k-instruct". this has 3.82B params. 
there was some trouble in loading all the models, the RAM ran out in kaggle everytime i ran the entire notebook. Hence i have ran the notebook in sections, that is per model.
Hence we have outputs from 2 models, but since the later 2 models did not load properly I just have the prompt printed out as the output. 

The prompt format was same for all models. There was no difference in the prompt format for any model. I asked chatgpt for it and then tweaked the parameters mentioned in it. 
